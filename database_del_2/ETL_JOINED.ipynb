{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ETL_JOINED.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGMX4QUp_Alk",
        "outputId": "ac4e1168-e88e-4c8c-e250-b374ca9e7abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connected to cloud.r-pro\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "spark_version = 'spark-3.0.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Postgres driver that will allow Spark to interact with Postgres.\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YJdkkYD_KVS",
        "outputId": "24c28d0c-3b47-4813-9645-1d8304a0b17a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-29 20:37:36--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar.2’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-01-29 20:37:36 (6.48 MB/s) - ‘postgresql-42.2.16.jar.2’ saved [1002883/1002883]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Final-Project\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ],
      "metadata": {
        "id": "u0neqVT7_Ncf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import col, when\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import lpad\n",
        "from pyspark.sql.functions import concat\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.sql.functions import substring"
      ],
      "metadata": {
        "id": "630cyNQk_PZa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles\n",
        "#url = \"https://finalprojectstorage10.s3.us-east-2.amazonaws.com/2018.csv\"\n",
        "url = \"https://storage.googleapis.com/uftairlinedbbucket/2018.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.option(\"encoding\", \"UTF-8\").csv(SparkFiles.get(\"2018.csv\"), header=True)\n",
        "#df.show()"
      ],
      "metadata": {
        "id": "qsxw2sYP_RnB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "#Timestamp function to fix formatting\n",
        "def padTimeStamp(x,y):\n",
        "  if y is None:\n",
        "      y = \"0\"\n",
        "\n",
        "  y = y.replace(\".0\",\"\")\n",
        "  return x + \" \" + y.zfill(4)[0:2] + \":\" + y.zfill(4)[2:4]\n",
        "\n",
        "#Create udf becuase python fucntions do not work with pyspark\n",
        "padTimeStampUDF = udf(lambda x,y: padTimeStamp(x,y)) \n",
        "\n",
        "#inital dataframe applying the udf to pad and format the timestamp columns and pick the rest of the columns\n",
        "initial_df = df.select(\n",
        "                    \"OP_CARRIER\",\n",
        "                    \"OP_CARRIER_FL_NUM\", \n",
        "                    \"ORIGIN\",\n",
        "                    padTimeStampUDF(df[\"FL_DATE\"],df[\"CRS_DEP_TIME\"]).alias(\"CRS_DEPARTURE_TIMESTAMP\"),\n",
        "                    df.columns[0],df.columns[4],\n",
        "                    padTimeStampUDF(df[\"FL_DATE\"],df[\"DEP_TIME\"]).alias(\"ACTUAL_DEPARTURE_TIMESTAMP\"),\n",
        "                    df.columns[7],df.columns[8],\n",
        "                    padTimeStampUDF(df[\"FL_DATE\"],df[\"WHEELS_OFF\"]).alias(\"WHEELS_OFF_TIMESTAMP\"),\n",
        "                    padTimeStampUDF(df[\"FL_DATE\"],df[\"WHEELS_ON\"]).alias(\"WHEELS_ON_TIMESTAMP\"),\n",
        "                    df.columns[11],\n",
        "                    padTimeStampUDF(df[\"FL_DATE\"],df[\"CRS_ARR_TIME\"]).alias(\"CRS_ARRIVAL_TIMESTAMP\"),\n",
        "                    padTimeStampUDF(df[\"FL_DATE\"],df[\"ARR_TIME\"]).alias(\"ACTUAL_ARRIVAL_TIMESTAMP\"), \n",
        "                    df.columns[14], df.columns[15], df.columns[16], df.columns[17], df.columns[18], df.columns[19], df.columns[20], df.columns[21], df.columns[22], df.columns[23], df.columns[24], df.columns[25], df.columns[26] \n",
        "                  )\n",
        "#initial_df.printSchema()\n",
        "#initial_df.show()\n",
        "\n",
        "#Changed the 1 and 0s to true and false\n",
        "initial_df = initial_df.withColumn(\"DIVERTED\", when(col(\"DIVERTED\") == '1.0', True).otherwise(False))\n",
        "initial_df = initial_df.withColumn(\"CANCELLED\", when(col(\"CANCELLED\") == '1.0', True).otherwise(False))\n",
        "\n",
        "#Final df where we change the column names and cast the datatypes\n",
        "final_df = initial_df.selectExpr(\n",
        "                                \"OP_CARRIER as AIRLINE_CARRIER_CODE\",\n",
        "                                \"OP_CARRIER_FL_NUM\",\n",
        "                                \"ORIGIN as ORIGIN_AIRPORT_CODE\",\n",
        "                                \"cast(CRS_DEPARTURE_TIMESTAMP as timestamp) CRS_DEPARTURE_TIMESTAMP\",\n",
        "                                \"cast(FL_DATE as date) FLIGHT_DT\",\n",
        "                                \"DEST as DEST_AIRPORT_CODE\",\n",
        "                                \"cast(ACTUAL_DEPARTURE_TIMESTAMP as timestamp) ACTUAL_DEPARTURE_TIMESTAMP\",\n",
        "                                \"cast(DEP_DELAY as integer) as DEPARTURE_DELAY_MINUTES\",\n",
        "                                \"cast(TAXI_OUT as integer) TAXI_OUT_MINUTES\",\n",
        "                                \"cast(WHEELS_OFF_TIMESTAMP as timestamp) WHEELS_OFF_TIMESTAMP\",\n",
        "                                \"cast(WHEELS_ON_TIMESTAMP as timestamp) WHEELS_ON_TIMESTAMP\",\n",
        "                                \"cast(TAXI_IN as integer) TAXI_IN_MINUTES\",\n",
        "                                \"cast(CRS_ARRIVAL_TIMESTAMP as timestamp) CRS_ARRIVAL_TIMESTAMP\",\n",
        "                                \"cast(CRS_ARRIVAL_TIMESTAMP as timestamp) ACTUAL_ARRIVAL_TIMESTAMP\",\n",
        "                                \"cast(ARR_DELAY as integer) ARRIVAL_DELAY_MINUTES\",\n",
        "                                \"CANCELLED as CANCELLED_IND\",\n",
        "                                \"CANCELLATION_CODE\",\n",
        "                                \"DIVERTED as DIVERTED_IND\",\n",
        "                                \"cast(CRS_ELAPSED_TIME as integer) CRS_ELAPSED_TIME_MINUTES\",\n",
        "                                \"cast(ACTUAL_ELAPSED_TIME as integer) ACTUAL_ELAPSED_TIME_MINUTES\",\n",
        "                                \"cast(AIR_TIME as integer) AIR_TIME_MINUTES\",\n",
        "                                \"cast(DISTANCE as integer) DISTANCE_MILES\",\n",
        "                                \"cast(CARRIER_DELAY as integer) CARRIER_DELAY_MINUTES\",\n",
        "                                \"cast(WEATHER_DELAY as integer) WEATHER_DELAY_MINUTES\",\n",
        "                                \"cast(NAS_DELAY as integer) NAS_DELAY_MINUTES\",\n",
        "                                \"cast(SECURITY_DELAY as integer) SECURITY_DELAY_MINUTES\",\n",
        "                                \"cast(LATE_AIRCRAFT_DELAY as integer) LATE_AIRCRAFT_DELAY_MINUTES\"\n",
        "                                )\n",
        "#Fill the null values with 0\n",
        "final_df = final_df.na.fill(value=0,subset=[\"CARRIER_DELAY_MINUTES\", \"WEATHER_DELAY_MINUTES\", \"NAS_DELAY_MINUTES\", \"SECURITY_DELAY_MINUTES\",\"LATE_AIRCRAFT_DELAY_MINUTES\"])\n",
        "\n",
        "#final_df.show()"
      ],
      "metadata": {
        "id": "FgifKHjx_68B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJhI9tBcADbt",
        "outputId": "9caa2eef-bdcd-4193-e673-6e290bd185da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- AIRLINE_CARRIER_CODE: string (nullable = true)\n",
            " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
            " |-- ORIGIN_AIRPORT_CODE: string (nullable = true)\n",
            " |-- CRS_DEPARTURE_TIMESTAMP: timestamp (nullable = true)\n",
            " |-- FLIGHT_DT: date (nullable = true)\n",
            " |-- DEST_AIRPORT_CODE: string (nullable = true)\n",
            " |-- ACTUAL_DEPARTURE_TIMESTAMP: timestamp (nullable = true)\n",
            " |-- DEPARTURE_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- TAXI_OUT_MINUTES: integer (nullable = true)\n",
            " |-- WHEELS_OFF_TIMESTAMP: timestamp (nullable = true)\n",
            " |-- WHEELS_ON_TIMESTAMP: timestamp (nullable = true)\n",
            " |-- TAXI_IN_MINUTES: integer (nullable = true)\n",
            " |-- CRS_ARRIVAL_TIMESTAMP: timestamp (nullable = true)\n",
            " |-- ACTUAL_ARRIVAL_TIMESTAMP: timestamp (nullable = true)\n",
            " |-- ARRIVAL_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- CANCELLED_IND: boolean (nullable = false)\n",
            " |-- CANCELLATION_CODE: string (nullable = true)\n",
            " |-- DIVERTED_IND: boolean (nullable = false)\n",
            " |-- CRS_ELAPSED_TIME_MINUTES: integer (nullable = true)\n",
            " |-- ACTUAL_ELAPSED_TIME_MINUTES: integer (nullable = true)\n",
            " |-- AIR_TIME_MINUTES: integer (nullable = true)\n",
            " |-- DISTANCE_MILES: integer (nullable = true)\n",
            " |-- CARRIER_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- WEATHER_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- NAS_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- SECURITY_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- LATE_AIRCRAFT_DELAY_MINUTES: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final_df.filter((final_df.AIRLINE_CARRIER_CODE == \"YX\") & (final_df.OP_CARRIER_FL_NUM == \"3624\") & (final_df.CRS_DEPARTURE_TIMESTAMP == '2018-06-21 20:07:00')).show(100)"
      ],
      "metadata": {
        "id": "ZyVxb-HICxDh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Airport Names "
      ],
      "metadata": {
        "id": "EQJV3CsfoQYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url2 = \"https://finalprojectstorage10.s3.us-east-2.amazonaws.com/airport.csv\"\n",
        "spark.sparkContext.addFile(url2)\n",
        "airport_initial_df = spark.read.option(\"encoding\", \"UTF-8\").csv(SparkFiles.get(\"airport.csv\"), header=True)\n",
        "#airport_initial_df.show()"
      ],
      "metadata": {
        "id": "JKmY5Cy_oZan"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select only relevant columns to later join with finaldf\n",
        "airport_df = airport_initial_df.select(\"iata_code\", \"name\", \"latitude_deg\", \"longitude_deg\")\n",
        "#airport_df.show()\n",
        "#airport_df.count()"
      ],
      "metadata": {
        "id": "OAf4AgmUpMaY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop null and duplicates\n",
        "airport_df = airport_df.dropna()\n",
        "airport_df = airport_df.drop_duplicates(['iata_code'])\n",
        "airport_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MFfVwRatJ0q",
        "outputId": "5ce9b40b-3802-433a-8b01-322485cac1e5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9131"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fix LAX NAME\n",
        "airport_df = airport_df.withColumn(\"name\", when(airport_df.name == \" \",\"Los Angeles International Airport\").otherwise(airport_df.name))\n"
      ],
      "metadata": {
        "id": "W3uG_qUgDj6n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "test_df = final_df\n",
        "#Origin Airport Code Join\n",
        "joined_df = test_df.join(airport_df, test_df.ORIGIN_AIRPORT_CODE == airport_df.iata_code,\"left\")\n",
        "joined_df = joined_df.withColumnRenamed(\"name\",\"ORIGIN_AIRPORT_NAME\").withColumnRenamed(\"latitude_deg\",\"ORIGIN_LATITUDE_DEG\").withColumnRenamed(\"longitude_deg\",\"ORIGIN_LONGITUDE_DEG\").drop(joined_df.iata_code)\n",
        "\n",
        "#Departure Airport Code Join and rename columns\n",
        "joined_df = joined_df.join(airport_df, joined_df.DEST_AIRPORT_CODE == airport_df.iata_code,\"left\")\n",
        "joined_df = joined_df.withColumnRenamed(\"name\",\"DEST_AIRPORT_NAME\").withColumnRenamed(\"latitude_deg\",\"DEST_LATITUDE_DEG\").withColumnRenamed(\"longitude_deg\",\"DEST_LONGITUDE_DEG\").drop(joined_df.iata_code)\n",
        "\n",
        "#Cast latitude and longitude to float\n",
        "joined_df = joined_df.withColumn(\"ORIGIN_LATITUDE_DEG\",col(\"ORIGIN_LATITUDE_DEG\").cast(FloatType())) \\\n",
        "                     .withColumn(\"ORIGIN_LONGITUDE_DEG\",col(\"ORIGIN_LONGITUDE_DEG\").cast(FloatType())) \\\n",
        "                     .withColumn(\"DEST_LATITUDE_DEG\",col(\"DEST_LATITUDE_DEG\").cast(FloatType())) \\\n",
        "                     .withColumn(\"DEST_LONGITUDE_DEG\",col(\"DEST_LONGITUDE_DEG\").cast(FloatType()))"
      ],
      "metadata": {
        "id": "1ruL82ZbviTB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y7587VMVig-",
        "outputId": "acfea3f0-01a8-4956-80a6-db56d794eaf3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- AIRLINE_CARRIER_CODE: string (nullable = true)\n",
            " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
            " |-- ORIGIN_AIRPORT_CODE: string (nullable = true)\n",
            " |-- CRS_DEPARTURE_TIMESTAMP: timestamp (nullable = true)\n",
            " |-- FLIGHT_DT: date (nullable = true)\n",
            " |-- DEST_AIRPORT_CODE: string (nullable = true)\n",
            " |-- ACTUAL_DEPARTURE_TIMESTAMP: timestamp (nullable = true)\n",
            " |-- DEPARTURE_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- TAXI_OUT_MINUTES: integer (nullable = true)\n",
            " |-- WHEELS_OFF_TIMESTAMP: timestamp (nullable = true)\n",
            " |-- WHEELS_ON_TIMESTAMP: timestamp (nullable = true)\n",
            " |-- TAXI_IN_MINUTES: integer (nullable = true)\n",
            " |-- CRS_ARRIVAL_TIMESTAMP: timestamp (nullable = true)\n",
            " |-- ACTUAL_ARRIVAL_TIMESTAMP: timestamp (nullable = true)\n",
            " |-- ARRIVAL_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- CANCELLED_IND: boolean (nullable = false)\n",
            " |-- CANCELLATION_CODE: string (nullable = true)\n",
            " |-- DIVERTED_IND: boolean (nullable = false)\n",
            " |-- CRS_ELAPSED_TIME_MINUTES: integer (nullable = true)\n",
            " |-- ACTUAL_ELAPSED_TIME_MINUTES: integer (nullable = true)\n",
            " |-- AIR_TIME_MINUTES: integer (nullable = true)\n",
            " |-- DISTANCE_MILES: integer (nullable = true)\n",
            " |-- CARRIER_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- WEATHER_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- NAS_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- SECURITY_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- LATE_AIRCRAFT_DELAY_MINUTES: integer (nullable = true)\n",
            " |-- ORIGIN_AIRPORT_NAME: string (nullable = true)\n",
            " |-- ORIGIN_LATITUDE_DEG: float (nullable = true)\n",
            " |-- ORIGIN_LONGITUDE_DEG: float (nullable = true)\n",
            " |-- DEST_AIRPORT_NAME: string (nullable = true)\n",
            " |-- DEST_LATITUDE_DEG: float (nullable = true)\n",
            " |-- DEST_LONGITUDE_DEG: float (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write to Database"
      ],
      "metadata": {
        "id": "ALr6HO1RoahF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure settings for RDS\n",
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://34.74.181.190:5432/airlinedb_final\"\n",
        "config = {\"user\":\"airlinedb\", \n",
        "          \"password\": \"KFG5ruuAfBBJGqhz\", \n",
        "          \"driver\":\"org.postgresql.Driver\"}\n"
      ],
      "metadata": {
        "id": "jox7vu8wAF_W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write Joined Dataframe to joined flightdata table in RDS\n",
        "joined_df.write.jdbc(url=jdbc_url, table='project.joined_flight_data', mode=mode, properties=config)"
      ],
      "metadata": {
        "id": "OuwZ267LAHdu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipecho.net/plain"
      ],
      "metadata": {
        "id": "aoYQ819kA-aC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1123fcb8-74e0-4e3a-ff20-b830e1d31b0f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.73.85.97"
          ]
        }
      ]
    }
  ]
}